{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb86c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2735c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = pd.read_csv('/home/prassanna/M/DL/TEXT/seq2seq/small_data.csv')\n",
    "train, testtemp = train_test_split(small_data, test_size=0.3, shuffle=True)\n",
    "val, test = train_test_split(testtemp, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f62f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "spacy_hi = spacy.load(\"xx_sent_ud_sm\") #multilang model\n",
    "\n",
    "def tokenize_hi(text):\n",
    "    return [tok.text for tok in spacy_hi.tokenizer(text)]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a25f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = train.iloc[:,1].values\n",
    "eng = train.iloc[:,2].values\n",
    "\n",
    "tok_hi =[(tokenize_hi(sent)) for sent in hindi]\n",
    "tok_eng =[(tokenize_eng(sent)) for sent in eng]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7713fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counter(tok_lang):\n",
    "    counter_lang = Counter()\n",
    "    for i in range(len(tok_lang)):\n",
    "        counter_lang.update(tok_lang[i]) \n",
    "    return counter_lang\n",
    "\n",
    "def build_vocab_with_spl(tok_lang):\n",
    "    counter_lang = get_counter(tok_lang)\n",
    "    sorted_by_freq_tuples_lang = sorted(counter_lang.items(), key=lambda x: x[1], reverse=True)\n",
    "    #text as a key,index as a value\n",
    "    ordered_dict_lang = OrderedDict(sorted_by_freq_tuples_lang)\n",
    "    voc_lang = vocab(ordered_dict_lang, min_freq=1)\n",
    "    spl_tok = ['<pad>', '<bos>', '<eos>', '<unk>']\n",
    "    spl_tok_idx = [0,1,2,3]\n",
    "    for (spl_tok,spl_tok_idx) in zip(spl_tok,spl_tok_idx):\n",
    "        voc_lang.insert_token(spl_tok, spl_tok_idx)\n",
    "    \n",
    "    default_index = voc_lang['<unk>']\n",
    "    voc_lang.set_default_index(default_index)\n",
    "    return voc_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247e2bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_eng = build_vocab_with_spl(tok_eng)\n",
    "voc_hi = build_vocab_with_spl(tok_hi)\n",
    "len(voc_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270a045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b16da1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_array(sent):\n",
    "    arr = [voc_eng([word]) for word in sent]\n",
    "    return arr, len(arr)\n",
    "\n",
    "def get_seq_len(data):\n",
    "    tok_data = [sent_array(tokenize_eng(sent)) for sent in data]\n",
    "    seq_vec = [i[0] for i in tok_data]\n",
    "    seq_len = torch.LongTensor([i[1] for i in tok_data])\n",
    "    \n",
    "    for idx,_ in enumerate(seq_vec):\n",
    "        seq_vec[idx] = [[voc_eng['<bos>']]] + seq_vec[idx] + [[voc_eng['<eos>']]]\n",
    "    \n",
    "    return seq_vec, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "21e5a3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_seq_len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "40f95107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a5faac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [22], [58], [18], [2]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b73a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [92], [16], [225], [226], [2]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d2ded655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(seq_vec, seq_len):\n",
    "    seq_tensor = torch.zeros((len(seq_vec), seq_len.max()+2)).long()\n",
    "    for idx, (seq_vec, seq_len) in enumerate(zip(seq_vec, seq_len)):\n",
    "        seq_tensor[idx,:seq_len] = torch.LongTensor(seq_vec)\n",
    "    return seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3f9646ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.LongTensor{[5, 1]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36mpad_sequences\u001b[0;34m(seq_vec, seq_len)\u001b[0m\n\u001b[1;32m      2\u001b[0m seq_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(seq_vec), seq_len\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (seq_vec, seq_len) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(seq_vec, seq_len)):\n\u001b[0;32m----> 4\u001b[0m     seq_tensor[idx,:seq_len] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(seq_vec)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq_tensor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.LongTensor{[5, 1]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "pad_sequences(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "60c7d3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7498b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_tensor = torch.zeros((len(x), y.max()+2)).long()\n",
    "\n",
    "q_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (x, y) in enumerate(zip(x, y)):\n",
    "    seq_tensor[idx,:y] = torch.LongTensor(x[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
