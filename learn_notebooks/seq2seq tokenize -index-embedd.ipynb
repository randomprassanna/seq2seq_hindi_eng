{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from torchtext.datasets import Multi30k\n",
    "import torchtext\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/prassanna/M/DL/TEXT/seq2seq/dataset/hindi_english_parallel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hindi</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
       "      <td>Give your application an accessibility workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
       "      <td>Accerciser Accessibility Explorer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the bottom panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n",
       "      <td>The default plugin layout for the top panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n",
       "      <td>A list of plugins that are disabled by default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561836</th>\n",
       "      <td>स्पष्टीकरण.–जहां इस उपधारा के अधीन हानि और लाभ...</td>\n",
       "      <td>स्पष्टीकरण.–जहां इस उपधारा के अधीन हानि और लाभ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561837</th>\n",
       "      <td>मैंने गौर किया है कि यह न केवल अपने महत्त्वपूर...</td>\n",
       "      <td>है। I note that this is a landmark meeting – n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561838</th>\n",
       "      <td>उन्होंने मेरे समक्ष जो प्रदर्शन किया उसमें से ...</td>\n",
       "      <td>है। In the presentations that they made before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561839</th>\n",
       "      <td>खाद्य और जल सुरक्षा; पर्यावरण की दृष्टि से वहन...</td>\n",
       "      <td>्त है। Issues such as food and water security;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561840</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1561841 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     hindi  \\\n",
       "0          अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n",
       "1                          एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n",
       "2                    निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "3                     ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n",
       "4        उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n",
       "...                                                    ...   \n",
       "1561836  स्पष्टीकरण.–जहां इस उपधारा के अधीन हानि और लाभ...   \n",
       "1561837  मैंने गौर किया है कि यह न केवल अपने महत्त्वपूर...   \n",
       "1561838  उन्होंने मेरे समक्ष जो प्रदर्शन किया उसमें से ...   \n",
       "1561839  खाद्य और जल सुरक्षा; पर्यावरण की दृष्टि से वहन...   \n",
       "1561840                                                NaN   \n",
       "\n",
       "                                                   english  \n",
       "0           Give your application an accessibility workout  \n",
       "1                        Accerciser Accessibility Explorer  \n",
       "2           The default plugin layout for the bottom panel  \n",
       "3              The default plugin layout for the top panel  \n",
       "4           A list of plugins that are disabled by default  \n",
       "...                                                    ...  \n",
       "1561836  स्पष्टीकरण.–जहां इस उपधारा के अधीन हानि और लाभ...  \n",
       "1561837  है। I note that this is a landmark meeting – n...  \n",
       "1561838  है। In the presentations that they made before...  \n",
       "1561839  ्त है। Issues such as food and water security;...  \n",
       "1561840                                                NaN  \n",
       "\n",
       "[1561841 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use multi language spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_hi = torchtext.data.utils.get_tokenizer(None, language='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['खाद्य', 'और', 'जल', 'सुरक्षा;', 'पर्यावरण', 'की', 'दृष्टि', 'से', 'वहन.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_hi(\" खाद्य और जल सुरक्षा; पर्यावरण की दृष्टि से वहन.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spacy tokenizer is better than inbuilt in torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_hi = spacy.load(\"xx_sent_ud_sm\") #multilang model\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_hi(text):\n",
    "    return [tok.text for tok in spacy_hi.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], dtype=float32),\n",
       " array([], dtype=float32),\n",
       " array([], dtype=float32),\n",
       " array([], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_hi(text):\n",
    "    return [tok.vector for tok in spacy_hi.tokenizer(text)]\n",
    "tokenize_hi('द्य और जल सु')\n",
    "vectorize_hi('द्य और जल सु')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you use the en_core_web_lg model, the pre-trained word vectors are used as features in the model, on the way to calculating the vectors that are stored in doc.tensor. The en_core_web_sm model doesn't have pre-trained vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = spacy_hi('my name')\n",
    "doc[0].vector\n",
    "doc[1].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so for hindi the model with multilang will not have vectorized pretarined vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so we have to vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenize_hi('खाद्य और जल सुरक्षा; पर्यावरण की दृष्टि से जल जल पर्यावरण वहन अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें')\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "counter = Counter(sample)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab_freq = vocab(ordered_dict, min_freq=1)\n",
    "\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "vocab = Vocab(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 21\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_freq), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13 4 2 0\n"
     ]
    }
   ],
   "source": [
    "print(vocab_freq['पर्यावरण'], vocab_freq['पहुंचनीयता'],vocab_freq['सुरक्षा'],vocab_freq['खाद्य'], vocab_freq['जल'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_freq[';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'य'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'खाद्य'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'द'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for i in range(len(vocab)):\n",
    "    all_tokens.append(vocab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['खाद्य',\n",
       " 'और',\n",
       " 'जल',\n",
       " 'सुरक्षा',\n",
       " ';',\n",
       " 'पर्यावरण',\n",
       " 'की',\n",
       " 'दृष्टि',\n",
       " 'से',\n",
       " 'वहन',\n",
       " 'अपने',\n",
       " 'अनुप्रयोग',\n",
       " 'को',\n",
       " 'पहुंचनीयता',\n",
       " 'व्यायाम',\n",
       " 'का',\n",
       " 'लाभ',\n",
       " 'दें']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_index(token):\n",
    "    return all_tokens.index(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index('व्यायाम')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index('खाद्य')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with million vocabulary we will have one hot vectors of million size instaed we can use mebeddings for encoding and finding relationsjhip between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so without one hot, we will index the tokens in vocabulary and vector embedding we be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tokenize_hi('खाद्य और जल सुरक्षा; पर्यावरण की दृष्टि से जल जल पर्यावरण वहन अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें')\n",
    "\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "counter = Counter(sample)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True) #text as a key,index as a value\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "voc = vocab(ordered_dict, min_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "1\n",
      "6\n",
      "7\n",
      "8\n",
      "0\n",
      "0\n",
      "1\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in sample:\n",
    "    print(voc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert these vocab index into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Vocab' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [111]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sample:\n\u001b[0;32m----> 2\u001b[0m     voc[i]\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(voc[i])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Vocab' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "for i in sample:\n",
    "    voc[i]=torch.tensor(voc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so do it inside embedding object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(voc)\n",
    "embedding_size = 30\n",
    "embedding = nn.Embedding(input_size, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([ 0.2938, -1.6488, -0.0622, -0.8910,  0.4180,  0.1570, -2.9281, -0.7466,\n",
      "        -0.6867, -0.2636, -0.7993,  1.9872, -0.2783, -0.2079,  2.1681, -1.0402,\n",
      "         1.4449, -1.2026,  1.6475, -0.1707, -0.8598,  0.4058,  0.0160, -0.8408,\n",
      "         0.2830, -0.2891, -0.1552, -0.0115,  0.6332, -1.2350],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "em = embedding(torch.tensor(voc[sample[0]]))\n",
    "print(type(em))\n",
    "print(em)\n",
    "print(em.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can always use ptrtrained embeddings such as FASTTEXT, GLOVE etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
